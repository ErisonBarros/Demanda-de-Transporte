---
title: "Spatial Regression Models"
output: github_document
---

```{r setup, include=FALSE, purl=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.path = "README_files/Spatialmodels/")
```

## Startup
##### Import data
```{r message=FALSE, warning=FALSE}
library(sf)
WIfinal = st_read("Data/Spatial/wi_final_census2_random4.shp")
class(WIfinal) #it is a spatial feature dataset
```
```{r eval=FALSE}
View(WIfinal)
```
```{r echo=F, purl=F}
knitr::kable(head(WIfinal))
```
##### Project your spatial data  
R does not know in which coordinate system our data is (`CRS = _NA_`), and assumes it is in **WGS84** ([read more about it here](https://en.wikipedia.org/wiki/World_Geodetic_System)). WGS84 is the global coordinate system for **GPS** data, for instance.  
But it is not projected in a plan, as a cartesian XY, so if we want do deal with distances in meters (and not angular distances), we should project the data in another CRS, the 3857 ([see more](https://epsg.io/3857)).
```{r}
st_crs(WIfinal) = 4326 #set the crs to WGS84
WIfinal = st_transform(WIfinal, 3857) #project the data
```

Let's look at the distribution of *Hispanic people* with a map, using a quantile classification.
```{r warning=FALSE}
summary(WIfinal$HISP_)
library(tmap) #tmap package
tm_shape(WIfinal) + 
  tm_polygons(style = "quantile", col = "HISP_", title= "Hispanic people", legend.hist = TRUE) +
  tm_legend(outside = TRUE, text.size = .8) 
```

You can use `tmap()` as interactive view mode. Example, using the same command.
```{r}
tmap_mode("view") #you can choose "plot" (as above) or "view"
tm_shape(WIfinal) + 
  tm_polygons(style = "quantile", col = "HISP_", title= "Hispanic people")
```

## Global spatial autocorrelation   
### For polygon geometry
#### Neighbors
The first step requires that we define “neighboring” polygons. This could refer to contiguous polygons, polygons within a certain distance band, or it could be non-spatial in nature and defined by social, political or cultural “neighbors”.

Here, we’ll adopt a contiguous neighbor definition where we’ll accept any contiguous polygon that shares at least on vertex (this is the “**queen**” case and is defined by setting the parameter `queen=TRUE`). If we required that at least one edge be shared between polygons then we would set `queen=FALSE` (**rook neighbours**).
```{r message=FALSE, warning=FALSE}
library(spdep)
neighbors <- poly2nb(WIfinal, queen=TRUE) #queen
neighbors
neighbors_rook <- poly2nb(WIfinal, queen=F) #rook
neighbors_rook
```


#### Weights
Next, we need to assign weights to each neighboring polygon. In this case, each neighboring polygon will be assigned equal weight (`style="W"`). Style can take values “**W**”, “**B**”, “**C**”, “**U**”, “**minmax**” and “**S**”.  
Use `?nb2listw` to see more details.
```{r}
weightsW = nb2listw(neighbors, style="W")
weightsW
```

### Moran's I test
The correlation score is between -1 and 1. Much like a correlation coefficient:

* **1** determines perfect positive spatial autocorrelation (so your data is clustered)
* **0** identifies the data is randomly distributed, and
* **-1** represents negative spatial autocorrelation (so dissimilar values are next to each other).

To get the Moran’s I value use the `moran.test()` function.

```{r}
moran.test(WIfinal$HISP_, weightsW)
```
> What can you say about this result? 

#### Moran test with Monte Carlo simulation
Note that the p-value computed from the `moran.test` function is not computed from an Monte Carlo simulation but analytically instead. This may not always prove to be the most accurate measure of significance.  
To test for significance using the Monte Carlo simulation method instead, use the `moran.mc` function.
```{r}
#for a Monte Carlo simulation with 600 rounds
moran.mc(WIfinal$HISP_, weightsW, nsim=599)
```

Plot the distribution (note that this is a density plot instead of a histogram).
```{r}
plot(moran.mc(WIfinal$HISP_, weightsW, nsim=599), main="", las=1) #density plot
```


## Local spatial autocorrelation
### Local Moran
##### Moran scatterplot
```{r}
moran.plot(WIfinal$HISP_, listw = weightsW)
```

Notice how the plot is split in 4 quadrants. The top right corner belongs to areas that have high level of Hispanic people and are surrounded by other areas that have above the average level of Hispanic people This are the high-high locations. The bottom left corner belongs to the low-low areas. These are areas with low level of Hispanic people and surrounded by areas with below average levels of Hispanic people. Both the high-high and low-low represent clusters.  
A high-high cluster is what you may refer to as a hot spot. And the low-low clusters represent cold spots. In the opposite diagonal we have spatial outliers. They are not outliers in the standard sense, extreme observations, they are outliers in that they are surrounded by areas that are very unlike them. So you could have high-low spatial outliers, areas with high levels of Hispanic people and low levels of surrounding Hispanic people, or low-high spatial outliers, areas that have themselves low levels of Hispanic people (or whatever else you are mapping) and that are surrounded by areas with above average levels of Hispanic people.

##### Local Moran statistics
```{r}
localmoranstats <- localmoran(WIfinal$HISP_, weightsW)
summary(localmoranstats)
```


The outputs of this statistics' table are defined as:

* Ii: local moran statistic. One for each area.
* E.Ii: expectation of local moran statistic
* Var.Ii: variance of local moran statistic
* Z.Ii: standard deviate of local moran statistic
* Pr(): p-value of local moran statistic

Let's map the local moran statistics `Ii` and p-value
```{r warning=FALSE}
moranmap <- cbind(WIfinal, localmoranstats) #first, bind the statistics to the original data
names(moranmap)[39] <- "Pvalue"	#change the name of this variable to make it easier to call it

tm_shape(moranmap) +
  tm_polygons(col = "Ii", style = "pretty", title = "local Moran's statistic") 
tm_shape(moranmap) +
  tm_polygons(
    col = "Pvalue",
    breaks = c(-Inf, 0.01, 0.05, 0.1, 0.15, Inf),
    palette = "-Blues",
    title = "local Moran's I p-values") 
```

A positive value for `Ii` indicates that the unit is surrounded by units with similar values.  
Notice that with this variable we only have significant values at a confidence level of 90% (pvalue > 0.1).
  
### LISA clusters 

>“**Everything is related to everything else, but near things are more related than distant things**.” - The First Law of Geography (Tobler)  

In order to produce the LISA map we need to do some previous work. First we are going to create some new variables that we are going to need.  
First we scale the variable of interest. When we scale `HISP_` what we are doing is re-scaling the values so that the mean is zero.  
We also want to account for the spatial dependence of our values, so we create a spatial lag variable with `lag.listw()`. Spatial lag is when the dependent variable $y$ in place $i$ is affected by the independent variables in both place $i$ and $j$. This will be important to keep in mind when considering spatial regression. With spatial lag in ordinary least square regression, the assumption of uncorrelated error terms is violated, because near things will have associated error terms. Similarly, the assumption of independent observations is also violated, as the observations are influenced by the other observations near them. As a result, the estimates are biased and inefficient. Spatial lag is suggestive of a possible diffusion process – events in one place predict an increased likelihood of similar events in neighboring places.

```{r}
#scale the variable of interest and save it to a new column
moranmap$HISP_scale <- as.vector(scale(moranmap$HISP_))
summary(moranmap$HISP_scale)
#create a spatial lag variable and save it to a new column
moranmap$HISP_lag <- lag.listw(weightsW, moranmap$HISP_scale)
summary(moranmap$HISP_lag)
```
Then we need to create a variable to distinguish in which quadrant each observation is (recall the Moran scatterplot!).
```{r message=FALSE, warning=FALSE}
library(tidyverse)
siglevel = 0.15 #we can change to different levels
moranmap <- moranmap %>%  mutate(quad_sig = ifelse(moranmap$HISP_scale > 0 & 
                              moranmap$HISP_lag > 0 & 
                              moranmap$Pvalue <= siglevel, 
                     "high-high",
                     ifelse(moranmap$HISP_scale <= 0 & 
                              moranmap$HISP_lag <= 0 & 
                              moranmap$Pvalue <= siglevel, 
                     "low-low", 
                     ifelse(moranmap$HISP_scale > 0 & 
                              moranmap$HISP_lag <= 0 & 
                              moranmap$Pvalue <= siglevel, 
                     "high-low",
                     ifelse(moranmap$HISP_scale <= 0 & 
                              moranmap$HISP_lag > 0 & 
                              moranmap$Pvalue <= siglevel,
                     "low-high", 
                     "non-significant")))))
moranmap$quad_sig = factor(moranmap$quad_sig)
table(moranmap$quad_sig)
```
And now let's put the results in a map!
```{r message=FALSE, warning=FALSE}
# palcolor = c("red",rgb(1,0,0,alpha=0.4),rgb(0,0,1,alpha=0.4),"blue", "white") #define the color palette for the 5 categories (HH, HL, LH, LL, NS)
palcolor = c("red", "white") #the color palette for only 2 categories
tmap_mode("plot")
tm_shape(moranmap)+
  tm_polygons(col = "quad_sig", palette = palcolor, title = "local moran statistic")+
  tm_legend(outside = TRUE) 
```
What can you conclude?  
Now, try with other variable, for example the % of Black people per tract (`PCTBLCK`).

**See more** [here](https://mgimond.github.io/Spatial/spatial-autocorrelation-in-r.html), [here](https://maczokni.github.io/crimemapping_textbook_bookdown/global-and-local-spatial-autocorrelation.html), and [here](https://rpubs.com/quarcs-lab/spatial-autocorrelation)

  

### For points
Some of these analysis may also be performed for points, instead of polygons. How?
##### Install packages
Install and load ape package
```{r message=FALSE, warning=FALSE}
# install.packages("ape")
library(ape)
```

##### Prepare data
It does not deal with ordered factors, zeros, or infinite distances.  
So we need to clean data first.
```{r eval=F}
str(TABLE)
TABLE$classfactor<-as.numeric(TABLE$CLASS) #make ordered factors as numeric
TABLE$classfactor<-factor(TABLE$classfactor)
TABLEmoran<-TABLE
TABLEmoran$geometry<-NULL #drop geometry
TABLEmoran<-na.omit(TABLEmoran) #remove cases with NA
TABLEmoran<-TABLEmoran[TABLEmoran$Orig_Lat!=0,] #Remove cases with Lat/Lon equals to zero
```

#### Distances matrix, from coordinates (Lat Long)
To calculate Moran’s I, we will need to generate a matrix of inverse distance weights. In the matrix, entries for pairs of points that are close together are higher than for pairs of points that are far apart. 
  
We can first generate a distance matrix, then take inverse of the matrix values and replace the diagonal entries with zero:
```{r eval=F}
DISTANCES <- as.matrix(dist(cbind(TABLEmoran$Orig_Long, TABLEmoran$Orig_Lat)))
DISTANCESinv <- 1/DISTANCES
diag(DISTANCESinv) <- 0 #diagonal as zero
DISTANCESinv[is.infinite(DISTANCESinv)] <- 0 #remove infinite distances
```
We have created a matrix where each off-diagonal entry [ _i_, _j_] in the matrix is equal to 1/(distance between point _i_ and point _j_). Note that this is just one of several ways in which we can calculate an inverse distance matrix.  

#### Moran's I test
We can now calculate Moran’s I using the command `Moran.I`.
```{r eval=F}
#First attempt
Moran.I(TABLEmoran$classfactor, DISTANCESinv)
#Remove distances over 15 km
DISTANCESbin <- (DISTANCES > 0 & DISTANCES <= 15000)

#Second attempt
Moran.I(TABLEmoran$classfactor, DISTANCESbin) #Moran’s I =0.012, p = .001
```

> **Note:** The result (observed) is the Moran's I value, and if it is enough close to zero, we can affirm (with p=...) that ther is not a spatial pattern, suggesting an aleatory distribution in space.
Tf the result was close to 1 or -1, it would suggest a pattern in distribuition in space.


**See more [here](https://stats.idre.ucla.edu/r/faq/how-can-i-calculate-morans-i-in-r/)**

## Spatial Regression Models
_work in progress_
Check more here, to perform SRL with R: 

* https://maczokni.github.io/crimemapping_textbook_bookdown/spatial-regression-models.html
* https://rpubs.com/quarcs-lab/tutorial-spatial-regression 
