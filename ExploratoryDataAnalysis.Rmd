---
title: "Exploratory Data Analysis"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.path = "README_files/EDA/")
```


## Chicago example exercise

#### We will use the example of the following Multiple linear regression chapter to perform an EDA.

Trip production of 57 Traffic Assignment Zones of Chicago in 1960's.

> Your task: Explore and analyse the dataset before going to the Multiple linear regression chapter.  

### Variables:

* `TODU`: Motorized Trips (private car or Public Transportation) per occupied dwelling unit;
* `ACO`: Average car ownership (cars per dwelling);
* `AHS`: Average household size;
* `SRI`: Social Rank Index:  
      1. proportion of blue-collar workers (e.g., construction, mining);  
      2. proportion of people with age higher than 25 years that have completed at least 8 year of education;
        (_**Note:** The SRI has its maximum value when there are no blue-collar workers and all adults have education            of at least 8 years_) 
* `UI`: Urbanization Index:  
      1. fertility rate, defined as the ratio of children under 5 years of age to  the female population of childbearing age;  
      2. female labor force participation rate, meaning the % of women who are in the labor force;  
      3. % of single family units to total dwelling units.

    The degree of urbanization index would be increased by
        a) lower fertility rate,
        b) higher female labor force participation rate, and
       c) higher proportion of single dwelling units.
      (_**Note:** High values for this index imply less attachment to the home_)

* `SI`:Segregation Index
   It measures the proportion of an area to which minority groups (e.g: non-whites, foreign-born, Eastern Europeans) live in isolation.
     (_**Note:** High values for this index imply that those communities are less prone to leaving their living areas and as such to having lower levels of mobility_)



#### Import Libraries
Let's begin!

For the first time, you will need to install some of the packages. 
Step by step: 

  1. Go to Packages on the lower right display window and click install
  2. Write the library you want to install and click "install"
  
Or... `install.packages("readxl","tidyverse")` etc...

Depending on the version of your R, `DataExplorer` may need to be installed from source, such as
```r
if (!require(devtools)) install.packages("devtools")
devtools::install_github("boxuancui/DataExplorer")
```

Now, import these libraries:
```{r message=FALSE, warning=FALSE, paged.print=TRUE}
library(readxl) #Library used to import excel files
library(tidyverse) # Library used in data science to perform exploratory data analysis
library(skimr) # Library used for providing a summary of the data
library(DataExplorer) # Library used in data science to perform exploratory data analysis
library(corrplot) # Library used for correlation plots
library(car) # Library used for testing autocorrelation (Durbin Watson)
library(olsrr) # Library used for testing multicollinearity (VIF, TOL, etc.)
```

#### Import dataset

```{r}
dataset <- read_excel("Data/TDM_Class3_MLR_Chicago_Example.xls") 
```

#### Check the structure of the dataset 
```{r}
str(dataset)
```

#### Take a first look at the dataset

```{r paged.print=TRUE}
head(dataset, 10)
```

#### Check the type and class of the dataset

```{r echo=TRUE, eval=FALSE} 
typeof(dataset)
class(dataset)
```

```{r echo=FALSE, purl = FALSE}
typeof(dataset)
class(dataset)
```

#### Transform the dataset into a dataframe

```{r}
df <- data.frame(dataset)
```

#### Compare the structure of the dataset with df

```{r}
str(dataset)
str(df)
```

> **Note:** The dataframe function transforms columns into variables and rows into observations. 

#### Take a look at the dataframe

```{r}
head(df, 10)
```

#### Show summary statistics
 
```{r}
skim(df)
```

#### Check missing data

Take a look where is the missing data
```{r}
is.na(df)
```

Check the number of missing data

```{r}
sum(is.na(df))
```

Plot the percentage of missing data
```{r}
plot_missing(df)
```

> **Note:** We do not have any missing data in the dataset. However, here are some functions that you can use in other datasets to treat missing data. 

#### Treat missing data

Let us create a new variable to demonstrate this example.

```{r echo=TRUE}
df_md <- data.frame(df)
```


* **Listwise deletion**. Delete observation (row) with incomplete information. 
```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
na.omit(df_md)
```

* **Pairwise deletion**. Delete only the row of missing value if the variable is used. Consider that the variable "TODU" has missing values.  

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
df_md[!is.na(df_md$TODU),]
```

> **Note:** Listwise deletion may lose a lot of information, while pairwise deletion considers diferent sizes of variables in the analysis, which may be a problem. Choosing one method or the other depends on the number of missing data, sample size and characteristics of your data.

* **Replace missing value with mean or median**

Let us suppose that the variable "TODU" has missing values and you want to replace it by the mean or median. 

```{r}
df_md$TODU[is.na(df_md$TODU)] <- mean(df_md$TODU, na.rm = T)

df_md$TODU[is.na(df_md$TODU)] <- median(df_md$TODU, na.rm = T)
```

> **Note**: Here are just some examples of how to treat missing data. Take a look at other methods such as the prediction model or K-nearest neighbor imputation. 

#### Detect Outliers  

* Examine the boxplots
  
```{r}
par(mar=c(5,2,1,1)) # Make labels fit in the boxplot
boxplot(df_md, las = 2)
```

Take the out the outliers from the variable SI

```{r}
outlier <- function(x){
  quant <- quantile(x, probs=c(0.25, 0.75))
  caps <- quantile(x, probs=c(0.05, 0.95))
  H <- 1.5* IQR(x, na.rm = TRUE)
  x[x < (quant[1] - H)] <- caps[1]
  x[x > (quant[2] + H)] <- caps[2]
  return(x)
}

df_md$SI=outlier(df_md$SI)
```

* Take a look again at the boxplots

```{r}
par(mar=c(5,2,1,1)) # Make labels fit in the boxplot
boxplot(df_md, las = 2)
```

* **Compare results of the dataset with and without the outliers**

**Data with outliers**
```{r}
mean(df$SI)
median(df$SI)
var(df$SI)
```

**Data without outliers**
```{r}
mean(df_md$SI)
median(df_md$SI)
var(df_md$SI)
```


> **Note:** There are many methods to treat outliers. This is just one of them. Try using other methods and evaluate the difference. In the next chapter we will demonstrate other methods of detecting outliers through the cook distance and QQ plot.    


#### Plot histograms of all the continuous variables

```{r}
plot_histogram(df)
```

> **Note**: Take a special look at TODU, and see if the variable looks like a normal distribution.  

#### Plot boxplots of each independent variable with TODU

```{r}
plot_boxplot(df, by = "TODU")
```

> **Note**: If you increase the average car ownership (ACO) it will tend to increase the number of trips per dwelling unit (TODU). This makes sense. Try analyzing the other relations and check if it is coherent. 

#### Plot correlation heatmaps

```{r}
res1 <- cor.mtest(df, conf.level = .95)

corrplot(cor(df), p.mat = res1$p, method = "number", type = "upper", order="hclust", sig.level = 0.05)
```


> **Note:** try putting into method "color" or "circle", and see the diference.

> **Note:** The pairwise correlations that are crossed are statistically insignificant.The null hypothesis is that correlation is zero.This means that the correlations are only significant when you reject the null hypothesis (pvalue < 0.05). 

Therefore, take a look at this example and check the pvalue of a crossed pair correlation: 

```{r}
cor.test(df$AHS, df$SI)
```

> **Note:** Correlation heatmaps only consider pairwise correlations and does not demonstrate multicollinearity.  


#### Now that you have done some descriptive analysis of the data, go to the next chapter. There you will see how to perform a Multiple Linear Regression model!

